{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training image classification using CIFAR10 dataset\n",
    "\n",
    "Here I'm using a number of different network architectures to perform image classification on the CIFAR10 dataset, using a number of techniques learnt in CS231n and fastai parts 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "transform = T.Compose([# Various transforms can be added in this pipeline for data augmentation\n",
    "                       T.RandomHorizontalFlip(),\n",
    "#                        T.Pad(2),\n",
    "#                        T.RandomCrop(32, 2),\n",
    "                       T.ToTensor(), \n",
    "#                        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                      ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=transform)\n",
    "cifar10_val   = dset.CIFAR10('./cs231n/datasets', train=True, download=True, transform=T.ToTensor())\n",
    "cifar10_test  = dset.CIFAR10('./cs231n/datasets', train=False, download=True, transform=T.ToTensor())\n",
    "\n",
    "loader_train = DataLoader(cifar10_train, batch_size=256, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "loader_val   = DataLoader(cifar10_val, batch_size=256, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "loader_test  = DataLoader(cifar10_test, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "it = iter(loader_train)\n",
    "x,y=next(it)\n",
    "\n",
    "img = x[4].numpy().transpose((1,2,0))\n",
    "#img = img * 0.5 + 0.5\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(gpu_dtype))\n",
    "            y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def check_accuracy(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use negative log likelihood loss with LogSoftmax.\n",
    "\n",
    "The negative log likelihood loss is useful to train a classification\n",
    "problem with `C` classes.\n",
    "\n",
    "The input given through a forward call is expected to contain\n",
    "log-probabilities of each class: input has to be a 2D Tensor of size\n",
    "`(minibatch, C)`\n",
    "\n",
    "Obtaining log-probabilities in a neural network is easily achieved by\n",
    "adding a  `LogSoftmax`  layer in the last layer of your network.\n",
    "You may use `CrossEntropyLoss` instead, if you prefer not to add an extra\n",
    "layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, h):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(h[i], h[i+1]) for i in range(len(h) - 1)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        for lyr in self.layers:\n",
    "            a = lyr(x)\n",
    "            x = F.relu(a)\n",
    "        return F.log_softmax(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.9642\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.7780\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.6860\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 1.6175\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 1.5840\n",
      "Checking accuracy on validation set\n",
      "Got 428 / 1000 correct (42.80)\n"
     ]
    }
   ],
   "source": [
    "model = LinearNet([32*32*3, 100, 100, 100, 100, 100, 10]).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv2d(3, 32, kernel_size = 7),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.BatchNorm2d(32),\n",
    "                                nn.MaxPool2d(kernel_size=2),\n",
    "                      \n",
    "                                Flatten(),\n",
    "                                nn.Linear(5408, 1024),\n",
    "                                nn.ReLU(inplace = True),\n",
    "                                nn.Linear(1024,10)).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.3967\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.1439\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.9472\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.8613\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.6729\n",
      "Checking accuracy on validation set\n",
      "Got 599 / 1000 correct (59.90)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, h, c):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Conv2d(h[i], h[i+1], kernel_size=3, stride=2)\n",
    "             for i in range(len(h) - 1)])\n",
    "        self.pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.out = nn.Linear(h[-1], c)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for lyr in self.layers:\n",
    "            x = F.relu(lyr(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.9235\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.7553\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.6522\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 1.5978\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 1.5454\n",
      "Checking accuracy on validation set\n",
      "Got 435 / 1000 correct (43.50)\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet([3, 20, 40, 80], 10).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False, padding=1)\n",
    "        self.a = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.m = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds  = x_chan.std (1)[:,None,None]\n",
    "        return (x-self.means) / self.stds *self.m + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i + 1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l in self.layers: x = l(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.3542\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.1776\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.0794\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.9380\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.8870\n",
      "Checking accuracy on validation set\n",
      "Got 588 / 1000 correct (58.80)\n"
     ]
    }
   ],
   "source": [
    "model = ConvBnNet([10, 20, 40, 80, 160], 10).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-4)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.7747\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.7354\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.7240\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.6517\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.6575\n",
      "Checking accuracy on validation set\n",
      "Got 680 / 1000 correct (68.00)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.4880\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.4239\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.4447\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.4356\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.3950\n",
      "Checking accuracy on validation set\n",
      "Got 670 / 1000 correct (67.00)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv-Relu-BatchNorm Net using PyTorch BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvReluBatchNorm(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(nf)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(F.relu(self.conv(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvReluBatchNormNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([ConvReluBatchNorm(layers[i], layers[i + 1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l in self.layers: \n",
    "            x = l(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.3439\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.1179\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.0044\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.9357\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.8829\n",
      "Checking accuracy on validation set\n",
      "Got 656 / 1000 correct (65.60)\n"
     ]
    }
   ],
   "source": [
    "model = ConvReluBatchNormNet([10, 20, 40, 80, 160], 10).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-4)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.8427\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.7849\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.6790\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.6527\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.6000\n",
      "Checking accuracy on validation set\n",
      "Got 672 / 1000 correct (67.20)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.5064\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.4721\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.4867\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.4417\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.4207\n",
      "Checking accuracy on validation set\n",
      "Got 709 / 1000 correct (70.90)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.4342\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.4094\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.4114\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.4070\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.3691\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper Convnet\n",
    "\n",
    "Use stride 1 Conv layers after each stride 2 conv to prevent size from reducing too quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers1 = nn.ModuleList([ConvReluBatchNorm(layers[i], layers[i + 1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([ConvReluBatchNorm(layers[i+1], layers[i + 1], stride=1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        \n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l1, l2 in zip(self.layers1, self.layers2): \n",
    "            x = l1(x)\n",
    "            x = l2(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.4290\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.1782\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.0197\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.9179\n",
      "Starting epoch 5 / 5\n"
     ]
    }
   ],
   "source": [
    "model = DeeperNet([10, 20, 40, 80, 160], 10).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-4)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 682 / 1000 correct (68.20)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.7812\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.6978\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.5768\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.5339\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.4568\n",
      "Checking accuracy on validation set\n",
      "Got 723 / 1000 correct (72.30)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.3481\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.3183\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.2188\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.2111\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.1945\n",
      "Checking accuracy on validation set\n",
      "Got 730 / 1000 correct (73.00)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.1784\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.1784\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.1307\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0886\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0973\n",
      "Checking accuracy on validation set\n",
      "Got 734 / 1000 correct (73.40)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayer(ConvReluBatchNorm):\n",
    "    def forward(self, x):\n",
    "        return x + super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers1 = nn.ModuleList([ConvReluBatchNorm(layers[i], layers[i + 1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], stride=1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], stride=1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l1, l2, l3 in zip(self.layers1, self.layers2, self.layers3): \n",
    "            x = l3(l2(l1(x)))\n",
    "            \n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.3973\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.1801\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.0845\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.9632\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.8868\n",
      "Checking accuracy on validation set\n",
      "Got 672 / 1000 correct (67.20)\n"
     ]
    }
   ],
   "source": [
    "model = Resnet([10, 20, 40, 80, 160], 10).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-4)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.1537\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.8289\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.7011\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.6564\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.5816\n",
      "Checking accuracy on validation set\n",
      "Got 729 / 1000 correct (72.90)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.5087\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.4095\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.3693\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.3219\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.2665\n",
      "Checking accuracy on validation set\n",
      "Got 740 / 1000 correct (74.00)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.1861\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.1026\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.1266\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0896\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0507\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.0561\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.0286\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.0820\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0310\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0571\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-5)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.0316\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.0188\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.0242\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0224\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0241\n",
      "Checking accuracy on validation set\n",
      "Got 780 / 1000 correct (78.00)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-5)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetWithDropout(nn.Module):\n",
    "    def __init__(self, layers, c, p):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers1 = nn.ModuleList([ConvReluBatchNorm(layers[i], layers[i + 1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], stride=1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], stride=1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l1, l2, l3 in zip(self.layers1, self.layers2, self.layers3): \n",
    "            x = l3(l2(l1(x)))\n",
    "            \n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop(x)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.6142\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.1826\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.8804\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.7093\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.5877\n",
      "Checking accuracy on validation set\n",
      "Got 728 / 1000 correct (72.80)\n"
     ]
    }
   ],
   "source": [
    "model = ResnetWithDropout([16, 32, 64, 128, 256], 10, 0.2).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.NLLLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.5210\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.4546\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.3882\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.3170\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.2540\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.1685\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.1490\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.1286\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.1124\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.1010\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.0981\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.0852\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.0625\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0304\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0258\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.0257\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.0396\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.0459\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0201\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0299\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.0145\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.0300\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.0201\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.0249\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.0247\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-5)\n",
    "for i in range(2):\n",
    "    train(model, loss_fn, optimizer, num_epochs=5)\n",
    "    check_accuracy(model, loader_val)\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-5)\n",
    "for i in range(2):\n",
    "    train(model, loss_fn, optimizer, num_epochs=5)\n",
    "    check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet\n",
    "\n",
    "Reference https://github.com/fastai/fastai/blob/master/courses/dl2/cifar10-darknet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks//2),\n",
    "        nn.BatchNorm2d(nf, momentum=0.01),\n",
    "        nn.LeakyReLU(negative_slope=0.1, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, ni):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_layer(ni, ni//2, ks=1)\n",
    "        self.conv2 = conv_layer(ni//2, ni, ks=3)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return x + self.conv2(self.conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def make_group_layer(self, ch_in, num_blocks, stride=1):\n",
    "        return [conv_layer(ch_in, ch_in*2, stride=stride)\n",
    "               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes, nf=32):\n",
    "        super().__init__()\n",
    "        layers = [conv_layer(3, nf, ks=3, stride=1)]\n",
    "        for i,nb in enumerate(num_blocks):\n",
    "            layers += self.make_group_layer(nf, nb, stride=2-(i==1))\n",
    "            nf *= 2\n",
    "        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 1.8752\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 1.4551\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 1.2158\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 1.0537\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.8694\n",
      "Checking accuracy on validation set\n",
      "Got 636 / 1000 correct (63.60)\n"
     ]
    }
   ],
   "source": [
    "model = Darknet([1, 2, 4, 6, 3], num_classes=10, nf=32).type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "torch.cuda.random.manual_seed(12345)\n",
    "model.apply(reset)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.7644\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.6648\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.6034\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.5473\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.5244\n",
      "Checking accuracy on validation set\n",
      "Got 762 / 1000 correct (76.20)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.3673\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.3365\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.3026\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.3045\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.2988\n",
      "Checking accuracy on validation set\n",
      "Got 854 / 1000 correct (85.40)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.2610\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.2324\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.2748\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.2118\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.2446\n",
      "Checking accuracy on validation set\n",
      "Got 858 / 1000 correct (85.80)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.2443\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.2183\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.2226\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.2290\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.1950\n",
      "Checking accuracy on validation set\n",
      "Got 860 / 1000 correct (86.00)\n",
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.2075\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.2117\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.1719\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.1883\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.2159\n",
      "Checking accuracy on validation set\n",
      "Got 865 / 1000 correct (86.50)\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=5e-5)\n",
    "for i in range(2):\n",
    "    train(model, loss_fn, optimizer, num_epochs=5)\n",
    "    check_accuracy(model, loader_val)\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-5)\n",
    "for i in range(2):\n",
    "    train(model, loss_fn, optimizer, num_epochs=5)\n",
    "    check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "t = 100, loss = 0.1960\n",
      "Starting epoch 2 / 5\n",
      "t = 100, loss = 0.1892\n",
      "Starting epoch 3 / 5\n",
      "t = 100, loss = 0.1620\n",
      "Starting epoch 4 / 5\n",
      "t = 100, loss = 0.1589\n",
      "Starting epoch 5 / 5\n",
      "t = 100, loss = 0.1603\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-6)\n",
    "train(model, loss_fn, optimizer, num_epochs=5)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "t = 100, loss = 0.1869\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n",
      "Starting epoch 1 / 1\n",
      "t = 100, loss = 0.1509\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n",
      "Starting epoch 1 / 1\n",
      "t = 100, loss = 0.1631\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n",
      "Starting epoch 1 / 1\n",
      "t = 100, loss = 0.1714\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n",
      "Starting epoch 1 / 1\n",
      "t = 100, loss = 0.1629\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-7)\n",
    "for i in range(5):\n",
    "    train(model, loss_fn, optimizer, num_epochs=1)\n",
    "    check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet with 1cycle learning using fastai\n",
    "\n",
    "See https://github.com/fastai/fastai/blob/master/courses/dl2/cifar10-darknet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "PATH = Path(\"../../data/cifar/\")\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "cwd = os.getcwd()\n",
    "train_path = '../../data/cifar/train/'\n",
    "# go through classes and make a directory for each one\n",
    "for class_now in classes:\n",
    "    path_now = train_path + class_now\n",
    "    if not os.path.exists(path_now):\n",
    "        os.makedirs(path_now)\n",
    "# go through classes and match them with file names\n",
    "# file names are e.g. '123_frog.png' so glob picks out all the e.g. frog files\n",
    "for class_now in classes:\n",
    "    identifier = train_path + '*' + class_now + '.png'\n",
    "    class_files = glob.glob(identifier)\n",
    "    file_destination = train_path + class_now\n",
    "    # move all frog files to proper class directory\n",
    "    for file_to_move in class_files:\n",
    "        shutil.move(file_to_move, file_destination)\n",
    "\n",
    "# do all the same but now for the test data\n",
    "test_path = '../../data/cifar/test/'\n",
    "for class_now in classes:\n",
    "    path_now = test_path + class_now\n",
    "    if not os.path.exists(path_now):\n",
    "        os.makedirs(path_now)\n",
    "for class_now in classes:\n",
    "    identifier = test_path + '*' + class_now + '.png'\n",
    "    class_files = glob.glob(identifier)\n",
    "    file_destination = test_path + class_now\n",
    "    for file_to_move in class_files:\n",
    "        shutil.move(file_to_move, file_destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "num_workers = num_cpus()//2\n",
    "bs=256\n",
    "sz=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Darknet([1, 2, 4, 6, 3], num_classes=10, nf=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33989de29d4e4c3683aff17b140e01e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      2.099655   4.288735   0.1889    \n",
      "    1      1.835397   1.774035   0.3326                     \n",
      "    2      1.610211   2.070968   0.2533                     \n",
      "    3      1.472613   2.283549   0.2535                     \n",
      "    4      1.296008   1.57996    0.4312                     \n",
      "    5      1.126326   1.211259   0.555                      \n",
      "    6      1.025275   1.069151   0.627                      \n",
      "    7      0.936571   1.174674   0.5896                      \n",
      "    8      0.847115   1.123143   0.5975                      \n",
      "    9      0.778557   1.070792   0.6194                      \n",
      "    10     0.735641   0.823801   0.7148                      \n",
      "    11     0.677862   0.918517   0.6899                      \n",
      "    12     0.639654   0.950375   0.6896                      \n",
      "    13     0.615389   0.860501   0.7153                      \n",
      "    14     0.579276   0.960796   0.6791                      \n",
      "    15     0.55317    0.954072   0.692                       \n",
      "    16     0.54086    0.936158   0.6821                      \n",
      "    17     0.496117   0.727167   0.7548                      \n",
      "    18     0.492717   0.601528   0.7925                      \n",
      "    19     0.459403   0.613712   0.7882                      \n",
      "    20     0.435836   0.924769   0.7032                      \n",
      "    21     0.38986    0.616703   0.7855                      \n",
      "    22     0.333711   0.46603    0.8435                      \n",
      "    23     0.271174   0.367546   0.8718                      \n",
      "    24     0.225298   0.347792   0.879                       \n",
      "    25     0.199436   0.369482   0.8781                      \n",
      "    26     0.184019   0.342977   0.8852                      \n",
      "    27     0.165933   0.311577   0.8966                      \n",
      "    28     0.138426   0.289523   0.9057                      \n",
      "    29     0.122114   0.283784   0.9073                      \n",
      "\n",
      "CPU times: user 6h 44min 2s, sys: 23min 37s, total: 7h 7min 40s\n",
      "Wall time: 6h 49min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.28378]), 0.9073]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(20, 20, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9157"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np(to_np(probs), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We get 91.57% accuracy on CIFAR10 using 1cycle training with a Darknet architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
